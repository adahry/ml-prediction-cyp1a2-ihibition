# -*- coding: utf-8 -*-
"""training.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1LJKG0A2fPUwwdKKTM36PiD0_unYyaat8
"""

import torch
from torch import nn
from torch_geometric.data import DataLoader


def train(train_dataset,valid_dataset, model, learning_rate, epochs, batch_size, print=False):

  train_loader = DataLoader(train_dataset, batch_size=batch_size)
  valid_loader = DataLoader(valid_dataset, batch_size=batch_size)
  gnn_model = model

  loss_function = nn.MSELoss()

  # define optimiser
  optimiser = torch.optim.Adam(gnn_model.parameters(), lr = learning_rate)

  train_loss = []
  val_loss = []

  for epoch in range(epochs):

      # set model to training mode
      gnn_model.train()
      training_loss = 0.0
      # loop over minibatches for training
      for batch in train_loader:
          optimiser.zero_grad()
          # compute current value of loss function via forward pass
          output = gnn_model(batch.x.float(), batch.edge_index, batch.edge_attr, batch.batch)
          loss_function_value = loss_function(output[:,0], torch.tensor(batch.y, dtype = torch.float32))
          training_loss += loss_function_value.item()

          # compute current gradient via backward pass
          loss_function_value.backward()

          # update model weights using gradient and optimisation method
          optimiser.step()

      train_loss.append(training_loss/ len(train_loader))

      valid_loss = 0.0
      model.eval()
      for batch in valid_loader:
        output = gnn_model(batch.x.float(), batch.edge_index, batch.edge_attr ,batch.batch)
        loss_function_value = loss_function(output[:,0], torch.tensor(batch.y, dtype = torch.float32))
        valid_loss = loss_function_value.item() * batch.x.float().size(0)

      val_loss.append(valid_loss / len(valid_loader))

      if print == True:
        print(f'Epoch {epoch+1} \t\t Training Loss: {training_loss / len(train_loader)} \t\t Validation Loss: {valid_loss / len(valid_loader)}')

  return train_loss, val_loss